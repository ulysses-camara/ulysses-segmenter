{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4890b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T13:57:23.914010Z",
     "start_time": "2023-03-03T13:57:21.621211Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import argparse\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics.functional as tF\n",
    "import pytorch_lightning as pl\n",
    "import tokenizers\n",
    "import datasets\n",
    "\n",
    "\n",
    "DEBUG_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e7dfc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T13:57:23.918031Z",
     "start_time": "2023-03-03T13:57:23.915293Z"
    }
   },
   "outputs": [],
   "source": [
    "class HFDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hfdf):\n",
    "        self.hfdf = hfdf\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.hfdf[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hfdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cae9a71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T15:56:43.660235Z",
     "start_time": "2023-03-03T15:56:43.639417Z"
    }
   },
   "outputs": [],
   "source": [
    "class LitSegmenterBaseline(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int,\n",
    "        tokenizer_uri: str,\n",
    "        dataset_uri: str,\n",
    "        batch_size: int,\n",
    "        num_layers: int = 1,\n",
    "        bidirectional: bool = True,\n",
    "        num_classes: int = 4,\n",
    "        pad_token: str = \"[PAD]\",\n",
    "    ):\n",
    "        super(LitSegmenterBaseline, self).__init__()\n",
    "\n",
    "        self.tokenizer = tokenizers.Tokenizer.from_file(tokenizer_uri)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.pad_id = self.tokenizer.get_vocab().get(pad_token, 0)\n",
    "\n",
    "        def fn_pad_sequences(batch):\n",
    "            X = [torch.tensor(x_i[\"input_ids\"], dtype=torch.int) for x_i in batch]\n",
    "            y = [torch.tensor(y_i[\"labels\"]) for y_i in batch]\n",
    "\n",
    "            X = nn.utils.rnn.pad_sequence(X, padding_value=self.pad_id, batch_first=True)\n",
    "            y = nn.utils.rnn.pad_sequence(y, padding_value=-100, batch_first=True)\n",
    "\n",
    "            return X, y\n",
    "\n",
    "        self.fn_pad_sequences = fn_pad_sequences\n",
    "\n",
    "        if isinstance(dataset_uri, str):\n",
    "            self.hfdf = datasets.load_from_disk(dataset_uri)\n",
    "            \n",
    "        else:\n",
    "            dfs = []\n",
    "            for uri in dataset_uri:\n",
    "                dfs.append(datasets.load_from_disk(uri))\n",
    "            \n",
    "            hfdf = {}\n",
    "            for key in dfs[0].keys():\n",
    "                hfdf[key] = datasets.concatenate_datasets([df[key] for df in dfs])\n",
    "            \n",
    "            self.hfdf = datasets.DatasetDict(hfdf)\n",
    "\n",
    "        print(self.hfdf)\n",
    "            \n",
    "        self.embeddings = nn.Embedding(\n",
    "            num_embeddings=self.tokenizer.get_vocab_size(),\n",
    "            embedding_dim=768,\n",
    "            padding_idx=self.pad_id,\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=768,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.0 if num_layers == 1 else 0.1,\n",
    "            bidirectional=bidirectional,\n",
    "            proj_size=0,\n",
    "        )\n",
    "\n",
    "        self.lin_out = nn.Linear(\n",
    "            (1 + int(bidirectional)) * hidden_size,\n",
    "            num_classes,\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = X\n",
    "\n",
    "        if isinstance(out, str):\n",
    "            out = self.tokenizer(out, return_tensors=\"pt\")\n",
    "            out = out[\"input_ids\"]\n",
    "\n",
    "        out = self.embeddings(out)\n",
    "        out, *_ = self.lstm(out)\n",
    "        out = self.lin_out(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_pred_metrics(y_preds, y, phase: str) -> dict[str, float]:\n",
    "        y_preds = y_preds.view(-1, y_preds.shape[-1])\n",
    "        y = y.view(-1).squeeze()\n",
    "\n",
    "        loss = F.cross_entropy(input=y_preds, target=y, ignore_index=-100)\n",
    "\n",
    "        non_pad_inds = [i for i, cls_i in enumerate(y) if cls_i != -100]\n",
    "\n",
    "        per_cls_recall = tF.recall(\n",
    "            preds=y_preds[non_pad_inds, ...],\n",
    "            target=y[non_pad_inds],\n",
    "            num_classes=4,\n",
    "            average=None,\n",
    "        )\n",
    "\n",
    "        per_cls_precision = tF.precision(\n",
    "            preds=y_preds[non_pad_inds, ...],\n",
    "            target=y[non_pad_inds],\n",
    "            num_classes=4,\n",
    "            average=None,\n",
    "        )\n",
    "\n",
    "        macro_precision = float(per_cls_precision.mean().item())\n",
    "        macro_recall = float(per_cls_recall.mean().item())\n",
    "        macro_f1_score = (\n",
    "            2.0 * macro_precision * macro_recall / (1e-8 + macro_precision + macro_recall)\n",
    "        )\n",
    "\n",
    "        out = {\n",
    "            f\"{(phase + '_') if phase != 'train' else ''}loss\": loss,\n",
    "            **{f\"{phase}_cls_{i}_precision\": float(val) for i, val in enumerate(per_cls_precision)},\n",
    "            **{f\"{phase}_cls_{i}_recall\": float(val) for i, val in enumerate(per_cls_recall)},\n",
    "            f\"{phase}_macro_precision\": macro_precision,\n",
    "            f\"{phase}_macro_recall\": macro_recall,\n",
    "            f\"{phase}_macro_f1_score\": macro_f1_score,\n",
    "        }\n",
    "\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def _agg_stats(step_outputs):\n",
    "        out = {}\n",
    "        agg_items = collections.defaultdict(list)\n",
    "\n",
    "        for items in step_outputs:\n",
    "            for key, val in items.items():\n",
    "                if not isinstance(val, torch.Tensor):\n",
    "                    val = torch.tensor(val)\n",
    "\n",
    "                agg_items[key].append(val)\n",
    "\n",
    "        for key, vals in agg_items.items():\n",
    "            avg_vals = float(torch.stack(vals).mean().item())\n",
    "            out[f\"avg_{key}\"] = avg_vals\n",
    "\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx: int):\n",
    "        X, y = batch\n",
    "        y_preds = self.forward(X)\n",
    "\n",
    "        out = self._compute_pred_metrics(y_preds, y, phase=\"train\")\n",
    "\n",
    "        self.log_dict(\n",
    "            out,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "\n",
    "        return out\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        out = self._agg_stats(training_step_outputs)\n",
    "\n",
    "        self.log_dict(\n",
    "            out,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            logger=True,\n",
    "        )\n",
    "\n",
    "#     def validation_step(self, batch, batch_idx: int):\n",
    "#         X, y = batch\n",
    "#         y_preds = self.forward(X)\n",
    "\n",
    "#         out = self._compute_pred_metrics(y_preds, y, phase=\"val\")\n",
    "\n",
    "#         self.log_dict(\n",
    "#             out,\n",
    "#             on_step=False,\n",
    "#             on_epoch=True,\n",
    "#             logger=True,\n",
    "#         )\n",
    "\n",
    "#         return out\n",
    "\n",
    "#     def validation_epoch_end(self, validation_step_outputs):\n",
    "#         out = self._agg_stats(validation_step_outputs)\n",
    "\n",
    "#         self.log_dict(\n",
    "#             out,\n",
    "#             on_step=False,\n",
    "#             on_epoch=True,\n",
    "#             logger=True,\n",
    "#         )\n",
    "\n",
    "    def test_step(self, batch, batch_idx: int):\n",
    "        X, y = batch\n",
    "        y_preds = self.forward(X)\n",
    "\n",
    "        out = self._compute_pred_metrics(y_preds, y, phase=\"test\")\n",
    "\n",
    "        self.log_dict(\n",
    "            out,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            logger=True,\n",
    "        )\n",
    "\n",
    "        return out\n",
    "\n",
    "    def test_epoch_end(self, test_step_outputs):\n",
    "        out = self._agg_stats(test_step_outputs)\n",
    "\n",
    "        self.log_dict(\n",
    "            out,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            logger=True,\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=5e-4)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.75)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        df_train = HFDataset(self.hfdf[\"train\"])\n",
    "\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            dataset=df_train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "            collate_fn=self.fn_pad_sequences,\n",
    "        )\n",
    "\n",
    "        return train_dataloader\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         df_eval = HFDataset(self.hfdf[\"eval\"])\n",
    "\n",
    "#         eval_dataloader = torch.utils.data.DataLoader(\n",
    "#             dataset=df_eval,\n",
    "#             batch_size=self.batch_size,\n",
    "#             shuffle=False,\n",
    "#             num_workers=8,\n",
    "#             collate_fn=self.fn_pad_sequences,\n",
    "#         )\n",
    "\n",
    "#         return eval_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        df_test = HFDataset(self.hfdf[\"test\"])\n",
    "\n",
    "        test_dataloader = torch.utils.data.DataLoader(\n",
    "            dataset=df_test,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=8,\n",
    "            collate_fn=self.fn_pad_sequences,\n",
    "        )\n",
    "\n",
    "        return test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2de7693b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-04T08:08:18.835017Z",
     "start_time": "2023-03-03T20:31:23.367990Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | embeddings | Embedding | 4.6 M \n",
      "1 | lstm       | LSTM      | 2.1 M \n",
      "2 | lin_out    | Linear    | 2.1 K \n",
      "-----------------------------------------\n",
      "6.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.7 M     Total params\n",
      "26.845    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 159808\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 2602\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b16579df682440f9468681f47016f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/nvme/segmentador/venvs/env3.9.10/lib/python3.9/site-packages/pytorch_lightning/callbacks/progress/base.py:207: UserWarning: The progress bar already tracks a metric with the name(s) 'loss' and `self.log('loss', ..., prog_bar=True)` will overwrite this value.  If this is undesired, change the name or override `get_metrics()` in the progress bar callback.\n",
      "  rank_zero_warn(\n",
      "/media/nvme/segmentador/venvs/env3.9.10/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1398: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `test(ckpt_path='best')` to use and best model checkpoint and avoid this warning or `ckpt_path=trainer.checkpoint_callback.last_model_path` to use the last model.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at /media/nvme/segmentador/notebooks/lightning_logs/version_15/checkpoints/epoch=9-step=12489.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /media/nvme/segmentador/notebooks/lightning_logs/version_15/checkpoints/epoch=9-step=12489.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1b3b1f8aaf4c798d4d5b0c396885e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_cls_0_precision': 0.998159646987915,\n",
      " 'avg_test_cls_0_recall': 0.999201774597168,\n",
      " 'avg_test_cls_1_precision': 0.9796888828277588,\n",
      " 'avg_test_cls_1_recall': 0.9497243165969849,\n",
      " 'avg_test_cls_2_precision': 0.9082029461860657,\n",
      " 'avg_test_cls_2_recall': 0.8206210136413574,\n",
      " 'avg_test_cls_3_precision': 0.6968904733657837,\n",
      " 'avg_test_cls_3_recall': 0.5787816643714905,\n",
      " 'avg_test_loss': 0.01663857512176037,\n",
      " 'avg_test_macro_f1_score': 0.8640515208244324,\n",
      " 'avg_test_macro_precision': 0.8957353830337524,\n",
      " 'avg_test_macro_recall': 0.8370822072029114,\n",
      " 'test_cls_0_precision': 0.998175323009491,\n",
      " 'test_cls_0_recall': 0.9992001056671143,\n",
      " 'test_cls_1_precision': 0.9800203442573547,\n",
      " 'test_cls_1_recall': 0.95093834400177,\n",
      " 'test_cls_2_precision': 0.9074270725250244,\n",
      " 'test_cls_2_recall': 0.8203122019767761,\n",
      " 'test_cls_3_precision': 0.6964413523674011,\n",
      " 'test_cls_3_recall': 0.580051839351654,\n",
      " 'test_loss': 0.01651456579566002,\n",
      " 'test_macro_f1_score': 0.8642488718032837,\n",
      " 'test_macro_precision': 0.8955160975456238,\n",
      " 'test_macro_recall': 0.8376255631446838}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def main(args):\n",
    "    configs = [\n",
    "#         (512, 32),\n",
    "        (256, 32),\n",
    "#         (128, 64),\n",
    "#         (64, 64),\n",
    "#         (32, 64),\n",
    "    ]\n",
    "\n",
    "    for hidden_size, batch_size in configs:\n",
    "        accumulate_grad_batches = 128 // batch_size\n",
    "\n",
    "        model = LitSegmenterBaseline(\n",
    "            hidden_size=hidden_size,\n",
    "            batch_size=batch_size,\n",
    "            tokenizer_uri=\"../tokenizers/6000_subwords/tokenizer.json\",\n",
    "            dataset_uri=[\n",
    "                \"./final_curated_dataset_for_training\",\n",
    "                \"../data/refined_datasets/ccjs_segmentados_train_test_splits/ccjs_segmentados_train_test_splits_curados\",\n",
    "                \"../data/refined_datasets/emendas_variadas_segmentadas_train_test_splits/emendas_variadas_train_test_splits\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        trainer = pl.Trainer.from_argparse_args(\n",
    "            args,\n",
    "            overfit_batches=0.001 if DEBUG_RUN else 0.0,\n",
    "            accumulate_grad_batches=accumulate_grad_batches,\n",
    "        )\n",
    "\n",
    "        trainer.fit(model)\n",
    "\n",
    "        if not DEBUG_RUN:\n",
    "            trainer.test()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "\n",
    "    args = parser.parse_args(\n",
    "        \"\"\"\n",
    "        --gpu 1\n",
    "        --max_epochs 10\n",
    "        --log_every_n_steps 1000\n",
    "        --precision 32\n",
    "    \"\"\".split()\n",
    "    )\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4bfd2",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## 512 hidden units (lr_scheduler etc)\n",
    "{'avg_test_cls_0_precision': 0.9982964396476746,\n",
    " 'avg_test_cls_0_recall': 0.9993011951446533,\n",
    " 'avg_test_cls_1_precision': 0.9845898747444153,\n",
    " 'avg_test_cls_1_recall': 0.9579233527183533,\n",
    " 'avg_test_cls_2_precision': 0.9040074944496155,\n",
    " 'avg_test_cls_2_recall': 0.8204734921455383,\n",
    " 'avg_test_cls_3_precision': 0.6785829663276672,\n",
    " 'avg_test_cls_3_recall': 0.5864138007164001,\n",
    " 'avg_test_loss': 0.01806369051337242,\n",
    " 'avg_test_macro_f1_score': 0.8640120029449463,\n",
    " 'avg_test_macro_precision': 0.8913691639900208,\n",
    " 'avg_test_macro_recall': 0.8410279750823975,\n",
    " 'test_cls_0_precision': 0.9982959032058716,\n",
    " 'test_cls_0_recall': 0.9993012547492981,\n",
    " 'test_cls_1_precision': 0.9845767617225647,\n",
    " 'test_cls_1_recall': 0.9579482078552246,\n",
    " 'test_cls_2_precision': 0.903980016708374,\n",
    " 'test_cls_2_recall': 0.820344090461731,\n",
    " 'test_cls_3_precision': 0.6786746978759766,\n",
    " 'test_cls_3_recall': 0.5857861638069153,\n",
    " 'test_loss': 0.018070800229907036,\n",
    " 'test_macro_f1_score': 0.8639229536056519,\n",
    " 'test_macro_precision': 0.8913817405700684,\n",
    " 'test_macro_recall': 0.8408451080322266}\n",
    "\n",
    "## 512 hidden units (regular setup)\n",
    "{'avg_test_cls_0_precision': 0.9982461929321289,\n",
    " 'avg_test_cls_0_recall': 0.9994046688079834,\n",
    " 'avg_test_cls_1_precision': 0.986571729183197,\n",
    " 'avg_test_cls_1_recall': 0.9582132697105408,\n",
    " 'avg_test_cls_2_precision': 0.9132260084152222,\n",
    " 'avg_test_cls_2_recall': 0.8215959072113037,\n",
    " 'avg_test_cls_3_precision': 0.7250827550888062,\n",
    " 'avg_test_cls_3_recall': 0.535641610622406,\n",
    " 'avg_test_loss': 0.010228903032839298,\n",
    " 'avg_test_macro_f1_score': 0.8643761277198792,\n",
    " 'avg_test_macro_precision': 0.905781626701355,\n",
    " 'avg_test_macro_recall': 0.8287138938903809,\n",
    " 'test_cls_0_precision': 0.9982464909553528,\n",
    " 'test_cls_0_recall': 0.9994055032730103,\n",
    " 'test_cls_1_precision': 0.9865930676460266,\n",
    " 'test_cls_1_recall': 0.9582584500312805,\n",
    " 'test_cls_2_precision': 0.9132982492446899,\n",
    " 'test_cls_2_recall': 0.8214690089225769,\n",
    " 'test_cls_3_precision': 0.7250284552574158,\n",
    " 'test_cls_3_recall': 0.5351755023002625,\n",
    " 'test_loss': 0.010232209227979183,\n",
    " 'test_macro_f1_score': 0.8643065094947815,\n",
    " 'test_macro_precision': 0.9057917594909668,\n",
    " 'test_macro_recall': 0.8285772800445557}\n",
    "\n",
    "## 256 hidden units (lr_scheduler)\n",
    "{'avg_test_cls_0_precision': 0.9983095526695251,\n",
    " 'avg_test_cls_0_recall': 0.9992923736572266,\n",
    " 'avg_test_cls_1_precision': 0.9841660857200623,\n",
    " 'avg_test_cls_1_recall': 0.9603431820869446,\n",
    " 'avg_test_cls_2_precision': 0.906660258769989,\n",
    " 'avg_test_cls_2_recall': 0.8225072026252747,\n",
    " 'avg_test_cls_3_precision': 0.6957836151123047,\n",
    " 'avg_test_cls_3_recall': 0.5835158228874207,\n",
    " 'avg_test_loss': 0.01692836359143257,\n",
    " 'avg_test_macro_f1_score': 0.8669429421424866,\n",
    " 'avg_test_macro_precision': 0.8962297439575195,\n",
    " 'avg_test_macro_recall': 0.8414146900177002,\n",
    " 'test_cls_0_precision': 0.9983090758323669,\n",
    " 'test_cls_0_recall': 0.9992936849594116,\n",
    " 'test_cls_1_precision': 0.9841693043708801,\n",
    " 'test_cls_1_recall': 0.9603489637374878,\n",
    " 'test_cls_2_precision': 0.9068716764450073,\n",
    " 'test_cls_2_recall': 0.822350025177002,\n",
    " 'test_cls_3_precision': 0.6960282921791077,\n",
    " 'test_cls_3_recall': 0.58326256275177,\n",
    " 'test_loss': 0.016935868188738823,\n",
    " 'test_macro_f1_score': 0.8669469952583313,\n",
    " 'test_macro_precision': 0.8963446021080017,\n",
    " 'test_macro_recall': 0.8413137197494507}\n",
    "\n",
    "## 256 hidden units (regular setup)\n",
    "{'avg_test_cls_0_precision': 0.9983312487602234,\n",
    " 'avg_test_cls_0_recall': 0.9993693232536316,\n",
    " 'avg_test_cls_1_precision': 0.9855096340179443,\n",
    " 'avg_test_cls_1_recall': 0.9620329737663269,\n",
    " 'avg_test_cls_2_precision': 0.9168782830238342,\n",
    " 'avg_test_cls_2_recall': 0.8202478289604187,\n",
    " 'avg_test_cls_3_precision': 0.7135547995567322,\n",
    " 'avg_test_cls_3_recall': 0.5649248957633972,\n",
    " 'avg_test_loss': 0.01007597055286169,\n",
    " 'avg_test_macro_f1_score': 0.8680000305175781,\n",
    " 'avg_test_macro_precision': 0.9035684466362,\n",
    " 'avg_test_macro_recall': 0.8366436958312988,\n",
    " 'test_cls_0_precision': 0.998330295085907,\n",
    " 'test_cls_0_recall': 0.999370276927948,\n",
    " 'test_cls_1_precision': 0.9855092763900757,\n",
    " 'test_cls_1_recall': 0.9620238542556763,\n",
    " 'test_cls_2_precision': 0.9171323776245117,\n",
    " 'test_cls_2_recall': 0.8202000856399536,\n",
    " 'test_cls_3_precision': 0.7137227058410645,\n",
    " 'test_cls_3_recall': 0.5646311640739441,\n",
    " 'test_loss': 0.010080181993544102,\n",
    " 'test_macro_f1_score': 0.8680046200752258,\n",
    " 'test_macro_precision': 0.9036736488342285,\n",
    " 'test_macro_recall': 0.8365563750267029}\n",
    "\n",
    "\n",
    "## 128 hidden units\n",
    "{'avg_test_cls_0_precision': 0.99830561876297,\n",
    " 'avg_test_cls_0_recall': 0.999434769153595,\n",
    " 'avg_test_cls_1_precision': 0.9863963723182678,\n",
    " 'avg_test_cls_1_recall': 0.960133969783783,\n",
    " 'avg_test_cls_2_precision': 0.9214738011360168,\n",
    " 'avg_test_cls_2_recall': 0.8192890286445618,\n",
    " 'avg_test_cls_3_precision': 0.7188460826873779,\n",
    " 'avg_test_cls_3_recall': 0.5316470861434937,\n",
    " 'avg_test_loss': 0.008982779458165169,\n",
    " 'avg_test_macro_f1_score': 0.8646918535232544,\n",
    " 'avg_test_macro_precision': 0.9062554240226746,\n",
    " 'avg_test_macro_recall': 0.8276262879371643,\n",
    " 'test_cls_0_precision': 0.9983052611351013,\n",
    " 'test_cls_0_recall': 0.9994353652000427,\n",
    " 'test_cls_1_precision': 0.9863983988761902,\n",
    " 'test_cls_1_recall': 0.9601314067840576,\n",
    " 'test_cls_2_precision': 0.9216869473457336,\n",
    " 'test_cls_2_recall': 0.8193143010139465,\n",
    " 'test_cls_3_precision': 0.7187364101409912,\n",
    " 'test_cls_3_recall': 0.5313534736633301,\n",
    " 'test_loss': 0.008986305445432663,\n",
    " 'test_macro_f1_score': 0.8646671175956726,\n",
    " 'test_macro_precision': 0.9062817692756653,\n",
    " 'test_macro_recall': 0.8275586366653442}\n",
    " \n",
    " ## 64 hidden units\n",
    " {'avg_test_cls_0_precision': 0.9981099367141724,\n",
    " 'avg_test_cls_0_recall': 0.9995588660240173,\n",
    " 'avg_test_cls_1_precision': 0.9872504472732544,\n",
    " 'avg_test_cls_1_recall': 0.9569665193557739,\n",
    " 'avg_test_cls_2_precision': 0.938145637512207,\n",
    " 'avg_test_cls_2_recall': 0.7984744310379028,\n",
    " 'avg_test_cls_3_precision': 0.8033229112625122,\n",
    " 'avg_test_cls_3_recall': 0.4425460398197174,\n",
    " 'avg_test_loss': 0.009166688658297062,\n",
    " 'avg_test_macro_f1_score': 0.8598015904426575,\n",
    " 'avg_test_macro_precision': 0.9317071437835693,\n",
    " 'avg_test_macro_recall': 0.7993864417076111,\n",
    " 'test_cls_0_precision': 0.9981100559234619,\n",
    " 'test_cls_0_recall': 0.9995586276054382,\n",
    " 'test_cls_1_precision': 0.9872363209724426,\n",
    " 'test_cls_1_recall': 0.9569570422172546,\n",
    " 'test_cls_2_precision': 0.938208818435669,\n",
    " 'test_cls_2_recall': 0.7985380291938782,\n",
    " 'test_cls_3_precision': 0.8028951287269592,\n",
    " 'test_cls_3_recall': 0.4424935579299927,\n",
    " 'test_loss': 0.00917029194533825,\n",
    " 'test_macro_f1_score': 0.8597609400749207,\n",
    " 'test_macro_precision': 0.931612491607666,\n",
    " 'test_macro_recall': 0.799386739730835}\n",
    " \n",
    " ## 32 hidden units\n",
    " {'avg_test_cls_0_precision': 0.997940182685852,\n",
    " 'avg_test_cls_0_recall': 0.9996035099029541,\n",
    " 'avg_test_cls_1_precision': 0.9890697002410889,\n",
    " 'avg_test_cls_1_recall': 0.9552433490753174,\n",
    " 'avg_test_cls_2_precision': 0.9365561604499817,\n",
    " 'avg_test_cls_2_recall': 0.785433292388916,\n",
    " 'avg_test_cls_3_precision': 0.7959164381027222,\n",
    " 'avg_test_cls_3_recall': 0.31288468837738037,\n",
    " 'avg_test_loss': 0.009863470681011677,\n",
    " 'avg_test_macro_f1_score': 0.8375892043113708,\n",
    " 'avg_test_macro_precision': 0.92987060546875,\n",
    " 'avg_test_macro_recall': 0.7632912397384644,\n",
    " 'test_cls_0_precision': 0.9979405999183655,\n",
    " 'test_cls_0_recall': 0.9996036887168884,\n",
    " 'test_cls_1_precision': 0.9890552759170532,\n",
    " 'test_cls_1_recall': 0.9552522897720337,\n",
    " 'test_cls_2_precision': 0.9367883801460266,\n",
    " 'test_cls_2_recall': 0.7855103015899658,\n",
    " 'test_cls_3_precision': 0.7954726219177246,\n",
    " 'test_cls_3_recall': 0.31284019351005554,\n",
    " 'test_loss': 0.009864856489002705,\n",
    " 'test_macro_f1_score': 0.8375713229179382,\n",
    " 'test_macro_precision': 0.9298143982887268,\n",
    " 'test_macro_recall': 0.7633016109466553}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
